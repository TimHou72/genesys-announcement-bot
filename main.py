import requests
import feedparser
import os
import hashlib
from datetime import datetime

# é…ç½®
RSS_URL = "https://help.mypurecloud.com/announcements/feed/"
MATTERMOST_WEBHOOK = os.getenv("MATTERMOST_WEBHOOK")
CACHE_FILE = "sent_hashes.txt"
MAX_CACHE_SIZE = 50  # åªä¿ç•™æœ€è¿‘ 50 ç­†ç´€éŒ„

def get_hash(text):
    """å°‡æ¨™é¡Œè½‰ç‚ºé›œæ¹Šå€¼ï¼Œæ¯”å°æ›´æº–ç¢º"""
    return hashlib.md5(text.encode('utf-8')).hexdigest()

def get_sent_hashes():
    if os.path.exists(CACHE_FILE):
        with open(CACHE_FILE, "r") as f:
            return [line.strip() for line in f.readlines()]
    return []

def save_hashes(hashes):
    # åªä¿ç•™æœ€å¾Œ 50 ç­†ï¼Œé¿å…æª”æ¡ˆéå¤§
    with open(CACHE_FILE, "w") as f:
        f.write("\n".join(hashes[-MAX_CACHE_SIZE:]))

def get_style(title):
    t = title.lower()
    if any(x in t for x in ["deprecation", "removal", "notice", "end of"]):
        return "#FF3333", "ğŸ”´ æ£„ç”¨/é‡å¤§é€šçŸ¥"
    if any(x in t for x in ["new", "feature", "launch", "introduced"]):
        return "#2ECC71", "ğŸŸ¢ æ–°åŠŸèƒ½ä¸Šç·š"
    if "api" in t:
        return "#3498DB", "ğŸ”µ API è®Šæ›´"
    return "#888888", "âšª ä¸€èˆ¬å…¬å‘Š"

def send_to_mattermost(entry):
    color, tag = get_style(entry.title)
    
    # æ ¼å¼åŒ–æ™‚é–“ (RSS çš„æ™‚é–“é€šå¸¸æ˜¯ GMT)
    published = entry.get('published', 'æœªçŸ¥æ™‚é–“')
    
    # æ“·å–æ‘˜è¦ (å–å‰ 100 å­—)
    summary = BeautifulSoup(entry.summary, "html.parser").get_text()[:100] + "..."

    payload = {
        "username": "Genesys Cloud Bot",
        "attachments": [{
            "color": color,
            "title": f"[{tag}] {entry.title}",
            "title_link": entry.link,
            "text": f"**ç™¼å¸ƒæ™‚é–“**: {published}\n**å…§å®¹æ‘˜è¦**: {summary}",
            "fields": [
                {"title": "ä¾†æº", "value": "Genesys Resource Center", "short": True},
                {"title": "é¡åˆ¥", "value": tag, "short": True}
            ],
            "footer": "Genesys Cloud è‡ªå‹•åŒ–ç›£æ§",
            "ts": int(datetime.now().timestamp())
        }]
    }
    try:
        r = requests.post(MATTERMOST_WEBHOOK, json=payload, timeout=10)
        r.raise_for_status()
    except Exception as e:
        print(f"ç™¼é€å¤±æ•—: {e}")

# åŸ·è¡Œé‚è¼¯
if __name__ == "__main__":
    from bs4 import BeautifulSoup # ç”¨æ–¼è™•ç†æ‘˜è¦ä¸­çš„ HTML

    sent_hashes = get_sent_hashes()
    feed = feedparser.parse(RSS_URL)
    
    if not feed.entries:
        print("ç„¡æ³•å–å¾— RSS Feed æˆ–å…§å®¹ç‚ºç©º")
        exit()

    new_hashes = []
    has_update = False

    # å€’åºè™•ç†ï¼ˆå¾èˆŠåˆ°æ–°ç™¼é€ï¼‰
    for entry in reversed(feed.entries[:10]):
        h = get_hash(entry.title)
        if h not in sent_hashes:
            print(f"è™•ç†æ–°å…¬å‘Š: {entry.title}")
            send_to_mattermost(entry)
            sent_hashes.append(h)
            has_update = True

    if has_update:
        save_hashes(sent_hashes)
    else:
        print("æª¢æŸ¥å®Œæˆï¼Œç„¡æ–°å…¬å‘Šã€‚")
